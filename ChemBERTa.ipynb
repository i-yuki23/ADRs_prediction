{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cfc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import wandb\n",
    "\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, IntervalStrategy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee65bc3",
   "metadata": {},
   "source": [
    "Loading the metrics we'll use to evaluate our model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fae6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = evaluate.load(\"roc_auc\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25daea6",
   "metadata": {},
   "source": [
    "Here we decide with evaluation to use and with dataset to test on\n",
    "\n",
    "In addition, we load the pre-trained model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fe51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_type = 'db_agree_no_dups'\n",
    "dataset_name = 'DrugBank'\n",
    "pretrained_path = \"seyonec/PubChem10M_SMILES_BPE_450k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc75558",
   "metadata": {},
   "source": [
    "here we load the dataset, we use train2 since it's the train file that doesn't contain the validation set insode of it.\n",
    "\n",
    "this ``load_dataset`` method, automatically loads all the files in csv format and creates an HuggingFace's dataset object that is easy to use when fine-tuning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8aee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac56ca23d011430892dacaadda6cbce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854614b117f846a0bd45b1485d3d2e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ad5ee4cb8a4c9d9f2d1d73cd34d762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da2230c6174708bde098bd62442d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58080f1dd739416cbbff5805c9fe6a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'split/{split_type}/{dataset_name}/train2.csv',\n",
    "                                          'validation': f'split/{split_type}/{dataset_name}/val.csv',\n",
    "                                          'test': f'split/{split_type}/{dataset_name}/test.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ef7af",
   "metadata": {},
   "source": [
    "removing uncessencary columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9b482f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column('withdrawn_class', 'labels').\\\n",
    "            remove_columns(['Unnamed: 0', 'index', 'length', 'inchikey', 'groups', 'source']).\\\n",
    "            with_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426a2ea",
   "metadata": {},
   "source": [
    "here we load our model and tokenizer, we use the ``AutoModel`` and ``AutoTokenizer`` classes as they provide a generic way to load every model in HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e41fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at seyonec/PubChem10M_SMILES_BPE_450k and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_path, num_labels=2,\n",
    "                                                           id2label={0: 'Not Withdrawn', 1:'Withdrawn'},\n",
    "                                                           label2id={'Not Withdrawn': 0, 'Withdrawn': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015dff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    \"\"\"this methods tokenize the smiles into ids which are then fed into the transforemr model\n",
    "    we set the max length of the toknizer to be the longest SMILES in our dataset and pad the rest to this length\"\"\"\n",
    "    return tokenizer(examples[\"smiles\"], padding=\"max_length\", truncation=True, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee51903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edce0ebeddb84f14bac8e0bed389f70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86eac71b463648f6ab99d395d87ea4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3204b3052ff24a57964b442f5153e3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['smiles', 'name', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3198\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['smiles', 'name', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['smiles', 'name', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1982\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045cb262",
   "metadata": {},
   "source": [
    "a method to compute all the metrics we are using to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927c5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    auc_score = auc.compute(prediction_scores=logits[:, 1], references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    aupr = average_precision_score(y_score=logits[:, 1], y_true=labels)\n",
    "    precision_score = precision.compute(predictions=predictions, references=labels)\n",
    "    recall_score = recall.compute(predictions=predictions, references=labels)\n",
    "    f1_score['F1'] = f1_score.pop('f1')\n",
    "    return {**f1_score , **{'PR-AUC': aupr}, **accuracy_score, **auc_score, **precision_score, **recall_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d63b47",
   "metadata": {},
   "source": [
    "here we define our entire training arguments\n",
    "this is a simple HuggingFace object that will contain all the parameters we are using in our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12cf250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./results/{split_type}/{dataset_name}/{pretrained_path}\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    report_to='wandb',\n",
    "    run_name=f'{pretrained_path} {split_type} {dataset_name}',\n",
    "    logging_steps=50,\n",
    "    save_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c621059a",
   "metadata": {},
   "source": [
    "training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfeaf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset={'Validation': dataset[\"validation\"], 'Test': dataset[\"test\"]},\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c4145d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1cb6fb372204f76b5da4b389cf28d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112387612875965, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ito/kth_project/DrugWithdrawn/wandb/run-20231118_185540-fqdrlre7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/i-yuki23/huggingface/runs/fqdrlre7' target=\"_blank\">seyonec/PubChem10M_SMILES_BPE_450k db_agree_no_dups DrugBank</a></strong> to <a href='https://wandb.ai/i-yuki23/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/i-yuki23/huggingface' target=\"_blank\">https://wandb.ai/i-yuki23/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/i-yuki23/huggingface/runs/fqdrlre7' target=\"_blank\">https://wandb.ai/i-yuki23/huggingface/runs/fqdrlre7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 02:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Validation F1</th>\n",
       "      <th>Validation Pr-auc</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Roc Auc</th>\n",
       "      <th>Validation Precision</th>\n",
       "      <th>Validation Recall</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Test Pr-auc</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Roc Auc</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556660</td>\n",
       "      <td>0.711729</td>\n",
       "      <td>0.721250</td>\n",
       "      <td>0.744522</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>1.336469</td>\n",
       "      <td>0.199472</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>0.388496</td>\n",
       "      <td>0.687427</td>\n",
       "      <td>0.112018</td>\n",
       "      <td>0.909639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.559600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.541935</td>\n",
       "      <td>0.735696</td>\n",
       "      <td>0.733750</td>\n",
       "      <td>0.774671</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.414474</td>\n",
       "      <td>1.702036</td>\n",
       "      <td>0.203136</td>\n",
       "      <td>0.203492</td>\n",
       "      <td>0.410192</td>\n",
       "      <td>0.699077</td>\n",
       "      <td>0.114527</td>\n",
       "      <td>0.897590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556034</td>\n",
       "      <td>0.748720</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.781655</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.424342</td>\n",
       "      <td>1.840887</td>\n",
       "      <td>0.212251</td>\n",
       "      <td>0.253607</td>\n",
       "      <td>0.441978</td>\n",
       "      <td>0.717339</td>\n",
       "      <td>0.120355</td>\n",
       "      <td>0.897590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.574949</td>\n",
       "      <td>0.757620</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>0.792737</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>0.460526</td>\n",
       "      <td>1.916616</td>\n",
       "      <td>0.211731</td>\n",
       "      <td>0.265939</td>\n",
       "      <td>0.443996</td>\n",
       "      <td>0.721366</td>\n",
       "      <td>0.120130</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.480400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.575053</td>\n",
       "      <td>0.762400</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.796616</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>2.045796</td>\n",
       "      <td>0.206848</td>\n",
       "      <td>0.260050</td>\n",
       "      <td>0.427346</td>\n",
       "      <td>0.716476</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>0.891566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.464800</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.581673</td>\n",
       "      <td>0.763162</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.798182</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>2.118418</td>\n",
       "      <td>0.203114</td>\n",
       "      <td>0.267199</td>\n",
       "      <td>0.406155</td>\n",
       "      <td>0.719790</td>\n",
       "      <td>0.114416</td>\n",
       "      <td>0.903614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ito/anaconda3/envs/project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.5239772542317709, metrics={'train_runtime': 151.6637, 'train_samples_per_second': 63.258, 'train_steps_per_second': 1.978, 'total_flos': 744663411741600.0, 'train_loss': 0.5239772542317709, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
